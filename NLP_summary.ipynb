{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraksi (Summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraksi adalah proses merangkum teks untuk menangkap makna utamanya. Teknik ini sering digunakan dalam pembuatan ringkasan otomatis. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained model for text summarization\n",
    "summarizer = pipeline('summarization')\n",
    "\n",
    "# Teks contoh\n",
    "text = \"\"\"OpenAI adalah perusahaan riset yang bertujuan untuk mengembangkan kecerdasan buatan dengan cara yang aman dan bermanfaat. \n",
    "          Mereka telah menciptakan berbagai model AI canggih, termasuk GPT-3, yang dapat melakukan berbagai tugas bahasa alami.\"\"\"\n",
    "\n",
    "# Buat ringkasan\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(\"Ringkasan:\", summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ekstraksi (Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekstraksi adalah proses menarik informasi tertentu dari teks, seperti entitas nama atau kata kunci. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Muat model spaCy untuk bahasa Inggris\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Teks contoh\n",
    "text = \"Elon Musk adalah CEO SpaceX dan Tesla. SpaceX berfokus pada eksplorasi ruang angkasa, sementara Tesla memproduksi kendaraan listrik.\"\n",
    "\n",
    "# Proses teks\n",
    "doc = nlp(text)\n",
    "\n",
    "# Ekstraksi entitas nama\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengklasifikasian Teks (Text Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teknik ini digunakan untuk mengkategorikan teks ke dalam kategori tertentu, seperti klasifikasi sentimen. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Data contoh\n",
    "texts = [\"I love this phone\", \"This movie is terrible\", \"I feel great about the service\"]\n",
    "labels = [\"positive\", \"negative\", \"positive\"]\n",
    "\n",
    "# Pipeline untuk teks klasifikasi\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(texts, labels)\n",
    "\n",
    "# Prediksi\n",
    "predicted_label = model.predict([\"I hate this movie\"])\n",
    "print(predicted_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Sentimen (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis sentimen digunakan untuk menentukan sikap atau perasaan yang terkandung dalam teks. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Teks contoh\n",
    "text = \"I love this product! It's amazing.\"\n",
    "blob = TextBlob(text)\n",
    "sentiment = blob.sentiment.polarity\n",
    "print(f\"Sentiment score: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengenalan Entitas Nama (Named Entity Recognition, NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER digunakan untuk mengidentifikasi entitas penting dalam teks, seperti nama orang, tempat, atau organisasi. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Muat model spaCy untuk bahasa Inggris\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Teks contoh\n",
    "text = \"Barack Obama was the 44th President of the United States.\"\n",
    "\n",
    "# Proses teks\n",
    "doc = nlp(text)\n",
    "\n",
    "# Ekstraksi entitas nama\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penandaan Bagian Kalimat (Part-of-Speech Tagging, POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tagging digunakan untuk mengidentifikasi jenis kata dalam kalimat. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Muat model spaCy untuk bahasa Inggris\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Teks contoh\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Proses teks\n",
    "doc = nlp(text)\n",
    "\n",
    "# Penandaan POS\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformatif (Transformers-based NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model berbasis transformer seperti BERT, GPT-3, dan T5 digunakan untuk berbagai tugas NLP termasuk pemahaman teks, pembuatan teks, dan penerjemahan. \\\n",
    "Berikut contoh kodenya: (Hugging Face Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained model for text generation\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generate text\n",
    "text = generator(\"Once upon a time\", max_length=50)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catatan:\n",
    "\n",
    "Akses ke Model: Akses ke model-model seperti GPT-3 dan Jurassic-1 Jumbo mungkin memerlukan pengaturan khusus atau biaya langganan. \\\n",
    "Performa: Performa model akan bervariasi tergantung pada tugas, data pelatihan, dan parameter yang digunakan. \\\n",
    "Fine-tuning: Untuk hasil yang lebih baik, Anda mungkin perlu melakukan fine-tuning model pada dataset khusus Anda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained GPT-3 model\n",
    "generator = pipeline('text-generation', model='gpt3')\n",
    "\n",
    "# Generate text\n",
    "prompt = \"Once upon a time, in a land far, far away...\"\n",
    "text = generator(prompt, max_length=100)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Generate text by filling the mask\n",
    "prompt = \"The quick brown fox jumps over the lazy [MASK].\"\n",
    "result = fill_mask(prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained T5 model\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\")\n",
    "\n",
    "# Generate a summary\n",
    "text = \"This is a very long and boring text. Can you please summarize it for me?\"\n",
    "summary = summarizer(text)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurasic-1 Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained Jurassic-1 Jumbo model\n",
    "# (Note: You might need to specify the correct model name and access details)\n",
    "generator = pipeline('text-generation', model='jurassic1-jumbo')\n",
    "\n",
    "# Generate text\n",
    "prompt = \"Write a poem about a robot who dreams of becoming a chef.\"\n",
    "text = generator(prompt, max_length=150)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembelajaran Representasi Teks (Text Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teknik ini mengubah teks menjadi representasi numerik yang dapat digunakan dalam model pembelajaran mesin. \\\n",
    "Beriktu contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Data contoh\n",
    "sentences = [[\"dog\", \"barks\"], [\"cat\", \"meows\"]]\n",
    "\n",
    "# Latih model Word2Vec\n",
    "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
    "\n",
    "# Dapatkan embedding untuk kata \"dog\"\n",
    "vector = model.wv['dog']\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penerjemahan Bahasa (Machine Translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teknik ini digunakan untuk menerjemahkan teks dari satu bahasa ke bahasa lain. \\\n",
    "Berikut contoh kodenya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer for translation\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Translate text\n",
    "text = \"Hello, how are you?\"\n",
    "translated = model.generate(**tokenizer.prepare_seq2seq_batch(text, return_tensors=\"pt\"))\n",
    "translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "print(translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
